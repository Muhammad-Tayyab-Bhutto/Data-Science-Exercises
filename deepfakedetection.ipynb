{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 16880,
          "databundleVersionId": 858837,
          "sourceType": "competition"
        },
        {
          "sourceId": 924245,
          "sourceType": "datasetVersion",
          "datasetId": 464091
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Tayyab-Bhutto/Data-Science-Exercises/blob/main/deepfakedetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing Required libraries"
      ],
      "metadata": {
        "id": "dFXIv9qNpKzt",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-12-09T19:19:40.446622Z",
          "iopub.execute_input": "2023-12-09T19:19:40.447491Z",
          "iopub.status.idle": "2023-12-09T19:19:40.451467Z",
          "shell.execute_reply.started": "2023-12-09T19:19:40.447455Z",
          "shell.execute_reply": "2023-12-09T19:19:40.450462Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --upgrade tensorflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T16:45:39.625247Z",
          "iopub.execute_input": "2023-12-09T16:45:39.625536Z",
          "iopub.status.idle": "2023-12-09T16:46:49.786238Z",
          "shell.execute_reply.started": "2023-12-09T16:45:39.625511Z",
          "shell.execute_reply": "2023-12-09T16:46:49.785367Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgmpE09AmZtN",
        "outputId": "faf95ba2-33c8-4f66-b266-374c20e4bb7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T16:46:49.788007Z",
          "iopub.execute_input": "2023-12-09T16:46:49.788324Z",
          "iopub.status.idle": "2023-12-09T16:47:01.724518Z",
          "shell.execute_reply.started": "2023-12-09T16:46:49.788290Z",
          "shell.execute_reply": "2023-12-09T16:47:01.723346Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npJijZHqmZtP",
        "outputId": "6d3c1769-4545-4039-80a4-6b0723639b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "TFSU3FCOpKzu",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:47:32.297111Z",
          "iopub.execute_input": "2023-12-09T16:47:32.297565Z",
          "iopub.status.idle": "2023-12-09T16:47:32.302727Z",
          "shell.execute_reply.started": "2023-12-09T16:47:32.297531Z",
          "shell.execute_reply": "2023-12-09T16:47:32.301738Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T16:47:37.888772Z",
          "iopub.execute_input": "2023-12-09T16:47:37.889146Z",
          "iopub.status.idle": "2023-12-09T16:47:38.566937Z",
          "shell.execute_reply.started": "2023-12-09T16:47:37.889115Z",
          "shell.execute_reply": "2023-12-09T16:47:38.566113Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ7n0WmCmZtS",
        "outputId": "61005e32-b02f-4117-cc77-df3589484b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T16:47:43.656709Z",
          "iopub.execute_input": "2023-12-09T16:47:43.657660Z",
          "iopub.status.idle": "2023-12-09T16:47:43.663303Z",
          "shell.execute_reply.started": "2023-12-09T16:47:43.657625Z",
          "shell.execute_reply": "2023-12-09T16:47:43.662459Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "57TQ-OmlmZtT",
        "outputId": "779f2ff6-8898-4eba-c112-af5bb189b80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ],
      "metadata": {
        "id": "8d4TH3NbpKzx",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:47:53.118551Z",
          "iopub.execute_input": "2023-12-09T16:47:53.119170Z",
          "iopub.status.idle": "2023-12-09T16:47:53.124459Z",
          "shell.execute_reply.started": "2023-12-09T16:47:53.119139Z",
          "shell.execute_reply": "2023-12-09T16:47:53.123572Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualisation"
      ],
      "metadata": {
        "id": "NL3Ht4wC9b3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_data():\n",
        "    return pd.read_csv('../input/deepfake-faces/metadata.csv')"
      ],
      "metadata": {
        "id": "jfv9PxSB4tM8",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:48:05.687192Z",
          "iopub.execute_input": "2023-12-09T16:48:05.687856Z",
          "iopub.status.idle": "2023-12-09T16:48:05.692250Z",
          "shell.execute_reply.started": "2023-12-09T16:48:05.687823Z",
          "shell.execute_reply": "2023-12-09T16:48:05.691329Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta=get_data()\n",
        "meta.head()"
      ],
      "metadata": {
        "id": "tDW7BRph9ehF",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:48:13.733457Z",
          "iopub.execute_input": "2023-12-09T16:48:13.734453Z",
          "iopub.status.idle": "2023-12-09T16:48:13.944029Z",
          "shell.execute_reply.started": "2023-12-09T16:48:13.734419Z",
          "shell.execute_reply": "2023-12-09T16:48:13.943211Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta.shape"
      ],
      "metadata": {
        "id": "n7FSdDifbZxn",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:49:21.917057Z",
          "iopub.execute_input": "2023-12-09T16:49:21.917924Z",
          "iopub.status.idle": "2023-12-09T16:49:21.923477Z",
          "shell.execute_reply.started": "2023-12-09T16:49:21.917890Z",
          "shell.execute_reply": "2023-12-09T16:49:21.922508Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(meta[meta.label=='FAKE']),len(meta[meta.label=='REAL'])"
      ],
      "metadata": {
        "id": "_FJcz2IthxVG",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:49:38.118177Z",
          "iopub.execute_input": "2023-12-09T16:49:38.118607Z",
          "iopub.status.idle": "2023-12-09T16:49:38.166602Z",
          "shell.execute_reply.started": "2023-12-09T16:49:38.118577Z",
          "shell.execute_reply": "2023-12-09T16:49:38.165764Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_df = meta[meta[\"label\"] == \"REAL\"]\n",
        "fake_df = meta[meta[\"label\"] == \"FAKE\"]\n",
        "sample_size = 8000\n",
        "\n",
        "real_df = real_df.sample(sample_size, random_state=42)\n",
        "fake_df = fake_df.sample(sample_size, random_state=42)\n",
        "\n",
        "sample_meta = pd.concat([real_df, fake_df])"
      ],
      "metadata": {
        "id": "IgMfzY-PjjtH",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:49:42.226691Z",
          "iopub.execute_input": "2023-12-09T16:49:42.227422Z",
          "iopub.status.idle": "2023-12-09T16:49:42.279253Z",
          "shell.execute_reply.started": "2023-12-09T16:49:42.227385Z",
          "shell.execute_reply": "2023-12-09T16:49:42.278459Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned instead of using 95k images we will only use 16000 images."
      ],
      "metadata": {
        "id": "xui-R3KBmZtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Train_set, Test_set = train_test_split(sample_meta,test_size=0.2,random_state=42,stratify=sample_meta['label'])\n",
        "Train_set, Val_set  = train_test_split(Train_set,test_size=0.3,random_state=42,stratify=Train_set['label'])"
      ],
      "metadata": {
        "id": "5eB86S6K-T5Z",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:52:15.896896Z",
          "iopub.execute_input": "2023-12-09T16:52:15.897378Z",
          "iopub.status.idle": "2023-12-09T16:52:15.943424Z",
          "shell.execute_reply.started": "2023-12-09T16:52:15.897347Z",
          "shell.execute_reply": "2023-12-09T16:52:15.942532Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_set.shape,Val_set.shape,Test_set.shape"
      ],
      "metadata": {
        "id": "8p-TONijb4qA",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:52:47.576639Z",
          "iopub.execute_input": "2023-12-09T16:52:47.577423Z",
          "iopub.status.idle": "2023-12-09T16:52:47.583547Z",
          "shell.execute_reply.started": "2023-12-09T16:52:47.577386Z",
          "shell.execute_reply": "2023-12-09T16:52:47.582606Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dict()\n",
        "\n",
        "y[0] = []\n",
        "y[1] = []\n",
        "\n",
        "for set_name in (np.array(Train_set['label']), np.array(Val_set['label']), np.array(Test_set['label'])):\n",
        "    y[0].append(np.sum(set_name == 'REAL'))\n",
        "    y[1].append(np.sum(set_name == 'FAKE'))\n",
        "\n",
        "trace0 = go.Bar(\n",
        "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
        "    y=y[0],\n",
        "    name='REAL',\n",
        "    marker=dict(color='#33cc33'),\n",
        "    opacity=0.7\n",
        ")\n",
        "trace1 = go.Bar(\n",
        "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
        "    y=y[1],\n",
        "    name='FAKE',\n",
        "    marker=dict(color='#ff3300'),\n",
        "    opacity=0.7\n",
        ")\n",
        "\n",
        "data = [trace0, trace1]\n",
        "layout = go.Layout(\n",
        "    title='Count of classes in each set',\n",
        "    xaxis={'title': 'Set'},\n",
        "    yaxis={'title': 'Count'}\n",
        ")\n",
        "\n",
        "fig = go.Figure(data, layout)\n",
        "iplot(fig)"
      ],
      "metadata": {
        "id": "hzNGtCWd-mTk",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:52:50.518619Z",
          "iopub.execute_input": "2023-12-09T16:52:50.519456Z",
          "iopub.status.idle": "2023-12-09T16:52:52.230366Z",
          "shell.execute_reply.started": "2023-12-09T16:52:50.519422Z",
          "shell.execute_reply": "2023-12-09T16:52:52.229468Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original image dataset were biased with more fake images than real since we are taking a sample of it its better to take equal proportion of real and fake images."
      ],
      "metadata": {
        "id": "YLajsTllmZti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for cur,i in enumerate(Train_set.index[25:50]):\n",
        "    plt.subplot(5,5,cur+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    plt.imshow(cv2.imread('../input/deepfake-faces/faces_224/'+Train_set.loc[i,'videoname'][:-4]+'.jpg'))\n",
        "\n",
        "    if(Train_set.loc[i,'label']=='FAKE'):\n",
        "        plt.xlabel('FAKE Image')\n",
        "    else:\n",
        "        plt.xlabel('REAL Image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VR7Uly2fcUYi",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:53:00.148987Z",
          "iopub.execute_input": "2023-12-09T16:53:00.149381Z",
          "iopub.status.idle": "2023-12-09T16:53:02.335001Z",
          "shell.execute_reply.started": "2023-12-09T16:53:00.149354Z",
          "shell.execute_reply": "2023-12-09T16:53:02.333906Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "dOvN_divkl-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before jumping to use pretrained model lets develop some base line model to test how our pretrained model outperforms."
      ],
      "metadata": {
        "id": "k_PYaRnomZtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom CNN Architecture"
      ],
      "metadata": {
        "id": "oid44Xx-pKz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retreive_dataset(set_name):\n",
        "    images,labels=[],[]\n",
        "    for (img, imclass) in zip(set_name['videoname'], set_name['label']):\n",
        "        images.append(cv2.imread('../input/deepfake-faces/faces_224/'+img[:-4]+'.jpg'))\n",
        "        if(imclass=='FAKE'):\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "\n",
        "    return np.array(images),np.array(labels)"
      ],
      "metadata": {
        "id": "Hz0ZdQ_fgHhG",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:53:40.746762Z",
          "iopub.execute_input": "2023-12-09T16:53:40.747610Z",
          "iopub.status.idle": "2023-12-09T16:53:40.753587Z",
          "shell.execute_reply.started": "2023-12-09T16:53:40.747577Z",
          "shell.execute_reply": "2023-12-09T16:53:40.752696Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_train=retreive_dataset(Train_set)\n",
        "X_val,y_val=retreive_dataset(Val_set)\n",
        "X_test,y_test=retreive_dataset(Test_set)"
      ],
      "metadata": {
        "id": "zeAGRcAbguKU",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:53:47.707109Z",
          "iopub.execute_input": "2023-12-09T16:53:47.707511Z",
          "iopub.status.idle": "2023-12-09T16:56:24.917050Z",
          "shell.execute_reply.started": "2023-12-09T16:53:47.707480Z",
          "shell.execute_reply": "2023-12-09T16:56:24.916023Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\",\n",
        "                        activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[224, 224, 3]),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    DefaultConv2D(filters=128),\n",
        "    DefaultConv2D(filters=128),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=128, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=64, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "34upiak4pKz6",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:56:32.628351Z",
          "iopub.execute_input": "2023-12-09T16:56:32.629239Z",
          "iopub.status.idle": "2023-12-09T16:56:33.351034Z",
          "shell.execute_reply.started": "2023-12-09T16:56:32.629193Z",
          "shell.execute_reply": "2023-12-09T16:56:33.350176Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T16:56:40.167191Z",
          "iopub.execute_input": "2023-12-09T16:56:40.168080Z",
          "iopub.status.idle": "2023-12-09T16:56:40.213141Z",
          "shell.execute_reply.started": "2023-12-09T16:56:40.168045Z",
          "shell.execute_reply": "2023-12-09T16:56:40.212263Z"
        },
        "trusted": true,
        "id": "IeYV7nRsmZtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=5,batch_size=64,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "KZbWeIBYpKz6",
        "execution": {
          "iopub.status.busy": "2023-12-09T16:56:46.966604Z",
          "iopub.execute_input": "2023-12-09T16:56:46.967070Z",
          "iopub.status.idle": "2023-12-09T19:06:49.455035Z",
          "shell.execute_reply.started": "2023-12-09T16:56:46.967034Z",
          "shell.execute_reply": "2023-12-09T19:06:49.454018Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'model' is your Keras model\n",
        "\n",
        "\n",
        "model.save('my_model.keras')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T19:06:53.277967Z",
          "iopub.execute_input": "2023-12-09T19:06:53.278262Z",
          "iopub.status.idle": "2023-12-09T19:06:57.246972Z",
          "shell.execute_reply.started": "2023-12-09T19:06:53.278237Z",
          "shell.execute_reply": "2023-12-09T19:06:57.245935Z"
        },
        "trusted": true,
        "id": "aQ0-CSJdmZto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "6HDDr4uehast",
        "execution": {
          "iopub.status.busy": "2023-12-09T19:09:19.883646Z",
          "iopub.execute_input": "2023-12-09T19:09:19.883975Z",
          "iopub.status.idle": "2023-12-09T19:11:30.074262Z",
          "shell.execute_reply.started": "2023-12-09T19:09:19.883946Z",
          "shell.execute_reply": "2023-12-09T19:11:30.073414Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have predictions (y_pred) from your model\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T19:16:56.462684Z",
          "iopub.execute_input": "2023-12-09T19:16:56.463457Z",
          "iopub.status.idle": "2023-12-09T19:19:10.020065Z",
          "shell.execute_reply.started": "2023-12-09T19:16:56.463424Z",
          "shell.execute_reply": "2023-12-09T19:19:10.019034Z"
        },
        "trusted": true,
        "id": "W7UsGXCimZto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_pred is a probability score, you may need to convert it to binary predictions\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:30.274453Z",
          "iopub.execute_input": "2023-12-09T08:09:30.275163Z",
          "iopub.status.idle": "2023-12-09T08:09:30.279526Z",
          "shell.execute_reply.started": "2023-12-09T08:09:30.275101Z",
          "shell.execute_reply": "2023-12-09T08:09:30.278579Z"
        },
        "trusted": true,
        "id": "LrO8YqmGmZtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:30.280922Z",
          "iopub.execute_input": "2023-12-09T08:09:30.281381Z",
          "iopub.status.idle": "2023-12-09T08:09:30.292728Z",
          "shell.execute_reply.started": "2023-12-09T08:09:30.281329Z",
          "shell.execute_reply": "2023-12-09T08:09:30.291808Z"
        },
        "trusted": true,
        "id": "aYJwW5MJmZtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:30.293922Z",
          "iopub.execute_input": "2023-12-09T08:09:30.294578Z",
          "iopub.status.idle": "2023-12-09T08:09:30.303553Z",
          "shell.execute_reply.started": "2023-12-09T08:09:30.294534Z",
          "shell.execute_reply": "2023-12-09T08:09:30.30266Z"
        },
        "trusted": true,
        "id": "Gv3tePvImZtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:30.304651Z",
          "iopub.execute_input": "2023-12-09T08:09:30.30507Z",
          "iopub.status.idle": "2023-12-09T08:09:30.312072Z",
          "shell.execute_reply.started": "2023-12-09T08:09:30.305026Z",
          "shell.execute_reply": "2023-12-09T08:09:30.311145Z"
        },
        "trusted": true,
        "id": "qbWf7FNTmZtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seaborn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:30.31322Z",
          "iopub.execute_input": "2023-12-09T08:09:30.313671Z",
          "iopub.status.idle": "2023-12-09T08:09:34.649031Z",
          "shell.execute_reply.started": "2023-12-09T08:09:30.313626Z",
          "shell.execute_reply": "2023-12-09T08:09:34.647971Z"
        },
        "trusted": true,
        "id": "cl18UNebmZtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming y_test and y_pred_binary are defined\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
        "\n",
        "# Plot confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=['Real', 'Fake'],\n",
        "            yticklabels=['Fake', 'Real'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:34.650263Z",
          "iopub.execute_input": "2023-12-09T08:09:34.650556Z",
          "iopub.status.idle": "2023-12-09T08:09:34.91293Z",
          "shell.execute_reply.started": "2023-12-09T08:09:34.650527Z",
          "shell.execute_reply": "2023-12-09T08:09:34.911479Z"
        },
        "trusted": true,
        "id": "aJ5wwPrJmZtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:34.914852Z",
          "iopub.execute_input": "2023-12-09T08:09:34.915427Z",
          "iopub.status.idle": "2023-12-09T08:09:35.114297Z",
          "shell.execute_reply.started": "2023-12-09T08:09:34.91536Z",
          "shell.execute_reply": "2023-12-09T08:09:35.113149Z"
        },
        "trusted": true,
        "id": "FEk4jnmNmZts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Assuming y_test and y_pred are defined\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "# Print TPR and FPR values\n",
        "for i, (fpr_value, tpr_value) in enumerate(zip(fpr, tpr)):\n",
        "    print(f'Threshold: {thresholds[i]:.4f}, FPR: {fpr_value:.4f}, TPR: {tpr_value:.4f}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:35.115332Z",
          "iopub.execute_input": "2023-12-09T08:09:35.11559Z",
          "iopub.status.idle": "2023-12-09T08:09:35.124532Z",
          "shell.execute_reply.started": "2023-12-09T08:09:35.115561Z",
          "shell.execute_reply": "2023-12-09T08:09:35.123841Z"
        },
        "trusted": true,
        "id": "HvBMSYOKmZts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot model performance\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, len(history.epoch) + 1)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Train Set')\n",
        "plt.plot(epochs_range, val_acc, label='Val Set')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Train Set')\n",
        "plt.plot(epochs_range, val_loss, label='Val Set')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:35.125406Z",
          "iopub.execute_input": "2023-12-09T08:09:35.125648Z",
          "iopub.status.idle": "2023-12-09T08:09:35.517244Z",
          "shell.execute_reply.started": "2023-12-09T08:09:35.125621Z",
          "shell.execute_reply": "2023-12-09T08:09:35.516579Z"
        },
        "trusted": true,
        "id": "PLYBfJPimZts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A baseline score of 50.06% is good to go let's finetune some pretrained model"
      ],
      "metadata": {
        "id": "n6B2QL2tmZt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Models for Transfer Learning"
      ],
      "metadata": {
        "id": "hqxnSBJ3pKz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i used Xception model for fine-tuning feel free to try the performance of other pretrained models."
      ],
      "metadata": {
        "id": "0kgicdatmZt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All three datasets contain individual images. We need to batch them, but for this we first need to ensure they all have the same size, or else batching will not work. We can use a `Resizing` layer for this. We must also call the `tf.keras.applications.xception.preprocess_input()` function to preprocess the images appropriately for the Xception model. We will also add shuffling and prefetching to the training dataset."
      ],
      "metadata": {
        "id": "gXG6iv8XpKz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_raw=tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "valid_set_raw=tf.data.Dataset.from_tensor_slices((X_val,y_val))\n",
        "test_set_raw=tf.data.Dataset.from_tensor_slices((X_test,y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:35.518072Z",
          "iopub.execute_input": "2023-12-09T08:09:35.518298Z",
          "iopub.status.idle": "2023-12-09T08:09:38.522478Z",
          "shell.execute_reply.started": "2023-12-09T08:09:35.518262Z",
          "shell.execute_reply": "2023-12-09T08:09:38.52166Z"
        },
        "trusted": true,
        "id": "r2x7Y_jHmZt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()  # extra code – resets layer name counter\n",
        "\n",
        "batch_size = 32\n",
        "preprocess = tf.keras.applications.xception.preprocess_input\n",
        "train_set = train_set_raw.map(lambda X, y: (preprocess(tf.cast(X, tf.float32)), y))\n",
        "train_set = train_set.shuffle(1000, seed=42).batch(batch_size).prefetch(1)\n",
        "valid_set = valid_set_raw.map(lambda X, y: (preprocess(tf.cast(X, tf.float32)), y)).batch(batch_size)\n",
        "test_set = test_set_raw.map(lambda X, y: (preprocess(tf.cast(X, tf.float32)), y)).batch(batch_size)"
      ],
      "metadata": {
        "id": "Bnz0n9XApKz9",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:38.523562Z",
          "iopub.execute_input": "2023-12-09T08:09:38.523845Z",
          "iopub.status.idle": "2023-12-09T08:09:38.720903Z",
          "shell.execute_reply.started": "2023-12-09T08:09:38.523814Z",
          "shell.execute_reply": "2023-12-09T08:09:38.720213Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look again at the first 9 images from the validation set: they're all with values ranging from -1 to 1:"
      ],
      "metadata": {
        "id": "ovNEMky-pKz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code – displays the first 9 images in the first batch of valid_set\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for X_batch, y_batch in valid_set.take(1):\n",
        "    for index in range(9):\n",
        "        plt.subplot(3, 3, index + 1)\n",
        "        plt.imshow((X_batch[index] + 1) / 2)  # rescale to 0–1 for imshow()\n",
        "        if(y_batch[index]==1):\n",
        "            classt='FAKE'\n",
        "        else:\n",
        "            classt='REAL'\n",
        "        plt.title(f\"Class: {classt}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZL3c3i4opKz9",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:38.721827Z",
          "iopub.execute_input": "2023-12-09T08:09:38.722071Z",
          "iopub.status.idle": "2023-12-09T08:09:40.180399Z",
          "shell.execute_reply.started": "2023-12-09T08:09:38.722043Z",
          "shell.execute_reply": "2023-12-09T08:09:40.179613Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42),\n",
        "    tf.keras.layers.RandomRotation(factor=0.05, seed=42),\n",
        "    tf.keras.layers.RandomContrast(factor=0.2, seed=42)\n",
        "])"
      ],
      "metadata": {
        "id": "Ib0cA8Y1pKz9",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:40.181384Z",
          "iopub.execute_input": "2023-12-09T08:09:40.181634Z",
          "iopub.status.idle": "2023-12-09T08:09:40.195862Z",
          "shell.execute_reply.started": "2023-12-09T08:09:40.181608Z",
          "shell.execute_reply": "2023-12-09T08:09:40.195172Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try running the following cell multiple times to see different random data augmentations:"
      ],
      "metadata": {
        "id": "G7GrQjsspKz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code – displays the same first 9 images, after augmentation\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for X_batch, y_batch in valid_set.take(1):\n",
        "    X_batch_augmented = data_augmentation(X_batch, training=True)\n",
        "    for index in range(9):\n",
        "        plt.subplot(3, 3, index + 1)\n",
        "        # We must rescale the images to the 0-1 range for imshow(), and also\n",
        "        # clip the result to that range, because data augmentation may\n",
        "        # make some values go out of bounds (e.g., RandomContrast in this case).\n",
        "        plt.imshow(np.clip((X_batch_augmented[index] + 1) / 2, 0, 1))\n",
        "        if(y_batch[index]==1):\n",
        "            classt='FAKE'\n",
        "        else:\n",
        "            classt='REAL'\n",
        "        plt.title(f\"Class: {classt}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w6GH5_vupKz-",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:40.196884Z",
          "iopub.execute_input": "2023-12-09T08:09:40.197124Z",
          "iopub.status.idle": "2023-12-09T08:09:41.776001Z",
          "shell.execute_reply.started": "2023-12-09T08:09:40.197099Z",
          "shell.execute_reply": "2023-12-09T08:09:41.775323Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load the pretrained model, without its top layers, and replace them with our own task"
      ],
      "metadata": {
        "id": "kNL9AOsDpKz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "                                                     include_top=False)\n",
        "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(avg)\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "lRyCgvaKpKz-",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:41.776943Z",
          "iopub.execute_input": "2023-12-09T08:09:41.777189Z",
          "iopub.status.idle": "2023-12-09T08:09:43.870669Z",
          "shell.execute_reply.started": "2023-12-09T08:09:41.777164Z",
          "shell.execute_reply": "2023-12-09T08:09:43.869916Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "KBlyG6ElpKz-",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:43.871679Z",
          "iopub.execute_input": "2023-12-09T08:09:43.871947Z",
          "iopub.status.idle": "2023-12-09T08:09:43.879268Z",
          "shell.execute_reply.started": "2023-12-09T08:09:43.871919Z",
          "shell.execute_reply": "2023-12-09T08:09:43.878579Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the model for a few epochs, while keeping the base model weights fixed:"
      ],
      "metadata": {
        "id": "WFEFw7GKpKz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=3)"
      ],
      "metadata": {
        "id": "GGxK2yPcpKz-",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:09:43.880176Z",
          "iopub.execute_input": "2023-12-09T08:09:43.880432Z",
          "iopub.status.idle": "2023-12-09T08:20:10.941026Z",
          "shell.execute_reply.started": "2023-12-09T08:09:43.880404Z",
          "shell.execute_reply": "2023-12-09T08:20:10.940128Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for indices in zip(range(33), range(33, 66), range(66, 99), range(99, 132)):\n",
        "    for idx in indices:\n",
        "        print(f\"{idx:3}: {base_model.layers[idx].name:22}\", end=\"\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "GvGMiJMLpKz-",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:20:10.948974Z",
          "iopub.execute_input": "2023-12-09T08:20:10.94932Z",
          "iopub.status.idle": "2023-12-09T08:20:10.971805Z",
          "shell.execute_reply.started": "2023-12-09T08:20:10.949253Z",
          "shell.execute_reply": "2023-12-09T08:20:10.971115Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:20:10.97301Z",
          "iopub.execute_input": "2023-12-09T08:20:10.973296Z",
          "iopub.status.idle": "2023-12-09T08:21:02.363463Z",
          "shell.execute_reply.started": "2023-12-09T08:20:10.973253Z",
          "shell.execute_reply": "2023-12-09T08:21:02.362579Z"
        },
        "trusted": true,
        "id": "1XT0BeqLmZuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model2.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T08:21:02.364759Z",
          "iopub.execute_input": "2023-12-09T08:21:02.365096Z",
          "iopub.status.idle": "2023-12-09T08:21:02.73191Z",
          "shell.execute_reply.started": "2023-12-09T08:21:02.365061Z",
          "shell.execute_reply": "2023-12-09T08:21:02.731037Z"
        },
        "trusted": true,
        "id": "n0wBoCCamZuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with the finetuning the top layers of xception model the model performance jumps to 63.8%"
      ],
      "metadata": {
        "id": "xXb0qIXbmZuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the weights of our new top layers are not too bad, we can make the top part of the base model trainable again, and continue training, but with a lower learning rate:"
      ],
      "metadata": {
        "id": "L_bEwL8KpKz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[56:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=3)"
      ],
      "metadata": {
        "id": "GEUNGlhvpKz_",
        "execution": {
          "iopub.status.busy": "2023-12-09T08:21:02.733236Z",
          "iopub.execute_input": "2023-12-09T08:21:02.733559Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('xception_deepfake_image.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:02:08.52496Z",
          "iopub.execute_input": "2023-12-09T09:02:08.525392Z",
          "iopub.status.idle": "2023-12-09T09:02:09.118948Z",
          "shell.execute_reply.started": "2023-12-09T09:02:08.525359Z",
          "shell.execute_reply": "2023-12-09T09:02:09.118127Z"
        },
        "trusted": true,
        "id": "NVvy6ZU0mZuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot model performance\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, len(history.epoch) + 1)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Train Set')\n",
        "plt.plot(epochs_range, val_acc, label='Val Set')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Train Set')\n",
        "plt.plot(epochs_range, val_loss, label='Val Set')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:11:46.254221Z",
          "iopub.execute_input": "2023-12-09T09:11:46.254578Z",
          "iopub.status.idle": "2023-12-09T09:11:46.653758Z",
          "shell.execute_reply.started": "2023-12-09T09:11:46.254549Z",
          "shell.execute_reply": "2023-12-09T09:11:46.652851Z"
        },
        "trusted": true,
        "id": "OCA2BHmwmZuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:02:26.007368Z",
          "iopub.execute_input": "2023-12-09T09:02:26.007739Z",
          "iopub.status.idle": "2023-12-09T09:03:13.243864Z",
          "shell.execute_reply.started": "2023-12-09T09:02:26.007707Z",
          "shell.execute_reply": "2023-12-09T09:03:13.242976Z"
        },
        "trusted": true,
        "id": "ZJjxVvBjmZuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "y_pred_probs = model.predict(test_set)\n",
        "y_true_list = [y.numpy() for _, y in test_set_raw]  # Convert TensorFlow tensors to NumPy arrays\n",
        "\n",
        "# Use np.hstack instead of np.concatenate\n",
        "y_true = np.hstack(y_true_list)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "y_pred_binary = (y_pred_probs > 0.5).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:08:55.068685Z",
          "iopub.execute_input": "2023-12-09T09:08:55.069026Z",
          "iopub.status.idle": "2023-12-09T09:09:44.139049Z",
          "shell.execute_reply.started": "2023-12-09T09:08:55.068996Z",
          "shell.execute_reply": "2023-12-09T09:09:44.137953Z"
        },
        "trusted": true,
        "id": "bIMypEhPmZuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have y_true and y_pred_binary from your previous code\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_binary)\n",
        "\n",
        "# Display confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:11:26.722716Z",
          "iopub.execute_input": "2023-12-09T09:11:26.723827Z",
          "iopub.status.idle": "2023-12-09T09:11:26.897225Z",
          "shell.execute_reply.started": "2023-12-09T09:11:26.723788Z",
          "shell.execute_reply": "2023-12-09T09:11:26.896316Z"
        },
        "trusted": true,
        "id": "_0txNcctmZuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:10:05.270518Z",
          "iopub.execute_input": "2023-12-09T09:10:05.270854Z",
          "iopub.status.idle": "2023-12-09T09:10:05.443411Z",
          "shell.execute_reply.started": "2023-12-09T09:10:05.270825Z",
          "shell.execute_reply": "2023-12-09T09:10:05.442558Z"
        },
        "trusted": true,
        "id": "8F9S_Gk3mZuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model accuracy finally reaches to 81.9%"
      ],
      "metadata": {
        "id": "AKFrK-0bmZuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try to interpret the trained model on how it finds a image FAKE"
      ],
      "metadata": {
        "id": "Keiadft7mZuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:12:07.503905Z",
          "iopub.execute_input": "2023-12-09T09:12:07.50495Z",
          "iopub.status.idle": "2023-12-09T09:12:17.668674Z",
          "shell.execute_reply.started": "2023-12-09T09:12:07.504913Z",
          "shell.execute_reply": "2023-12-09T09:12:17.667355Z"
        },
        "trusted": true,
        "id": "7IA2aDSOmZuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime import lime_image\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:12:21.589243Z",
          "iopub.execute_input": "2023-12-09T09:12:21.589629Z",
          "iopub.status.idle": "2023-12-09T09:12:21.824619Z",
          "shell.execute_reply.started": "2023-12-09T09:12:21.589594Z",
          "shell.execute_reply": "2023-12-09T09:12:21.823621Z"
        },
        "trusted": true,
        "id": "8DeEvRjPmZuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Fake Video Classification"
      ],
      "metadata": {
        "id": "QnR8BJ4EmZuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "rLniCHDemZuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --upgrade tensorflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:36:32.198745Z",
          "iopub.execute_input": "2023-12-09T09:36:32.199135Z",
          "iopub.status.idle": "2023-12-09T09:36:46.803516Z",
          "shell.execute_reply.started": "2023-12-09T09:36:32.199106Z",
          "shell.execute_reply": "2023-12-09T09:36:46.802431Z"
        },
        "trusted": true,
        "id": "dd49lmHVmZuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-docs\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:36:52.348998Z",
          "iopub.execute_input": "2023-12-09T09:36:52.349348Z",
          "iopub.status.idle": "2023-12-09T09:37:05.22909Z",
          "shell.execute_reply.started": "2023-12-09T09:36:52.349319Z",
          "shell.execute_reply": "2023-12-09T09:37:05.227933Z"
        },
        "trusted": true,
        "id": "VOYqoePhmZuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "#from imutils import paths\n",
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:37:28.502279Z",
          "iopub.execute_input": "2023-12-09T09:37:28.5032Z",
          "iopub.status.idle": "2023-12-09T09:37:28.914846Z",
          "shell.execute_reply.started": "2023-12-09T09:37:28.503148Z",
          "shell.execute_reply": "2023-12-09T09:37:28.913854Z"
        },
        "trusted": true,
        "id": "V6AFtwa3mZug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualisation"
      ],
      "metadata": {
        "id": "4ctN8G-hmZuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER = '../input/deepfake-detection-challenge'\n",
        "TRAIN_SAMPLE_FOLDER = 'train_sample_videos'\n",
        "TEST_FOLDER = 'test_videos'\n",
        "\n",
        "print(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
        "print(f\"Test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:37:44.634768Z",
          "iopub.execute_input": "2023-12-09T09:37:44.635181Z",
          "iopub.status.idle": "2023-12-09T09:37:44.643436Z",
          "shell.execute_reply.started": "2023-12-09T09:37:44.635149Z",
          "shell.execute_reply": "2023-12-09T09:37:44.642331Z"
        },
        "trusted": true,
        "id": "Ii5NdT27mZui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata = pd.read_json('../input/deepfake-detection-challenge/train_sample_videos/metadata.json').T\n",
        "train_sample_metadata.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:37:50.680821Z",
          "iopub.execute_input": "2023-12-09T09:37:50.681466Z",
          "iopub.status.idle": "2023-12-09T09:37:50.793851Z",
          "shell.execute_reply.started": "2023-12-09T09:37:50.681435Z",
          "shell.execute_reply": "2023-12-09T09:37:50.79291Z"
        },
        "trusted": true,
        "id": "HLnNNDCdmZui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata.groupby('label')['label'].count().plot(figsize=(15, 5), kind='bar', title='Distribution of Labels in the Training Set')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:37:52.992764Z",
          "iopub.execute_input": "2023-12-09T09:37:52.993485Z",
          "iopub.status.idle": "2023-12-09T09:37:53.342588Z",
          "shell.execute_reply.started": "2023-12-09T09:37:52.993454Z",
          "shell.execute_reply": "2023-12-09T09:37:53.341586Z"
        },
        "trusted": true,
        "id": "a7E4zl-KmZui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:37:54.741632Z",
          "iopub.execute_input": "2023-12-09T09:37:54.742036Z",
          "iopub.status.idle": "2023-12-09T09:37:54.748355Z",
          "shell.execute_reply.started": "2023-12-09T09:37:54.742003Z",
          "shell.execute_reply": "2023-12-09T09:37:54.747367Z"
        },
        "trusted": true,
        "id": "KlkcM0UymZuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize now the data.\n",
        "\n",
        "We select first a list of fake videos."
      ],
      "metadata": {
        "id": "hKEg4V7mmZuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few fake videos"
      ],
      "metadata": {
        "id": "8iaphuu5mZuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].sample(3).index)\n",
        "fake_train_sample_video"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:37:58.690213Z",
          "iopub.execute_input": "2023-12-09T09:37:58.690637Z",
          "iopub.status.idle": "2023-12-09T09:37:58.70123Z",
          "shell.execute_reply.started": "2023-12-09T09:37:58.6906Z",
          "shell.execute_reply": "2023-12-09T09:37:58.70017Z"
        },
        "trusted": true,
        "id": "qqiXxoCKmZuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_from_video(video_path):\n",
        "    '''\n",
        "    input: video_path - path for video\n",
        "    process:\n",
        "    1. perform a video capture from the video\n",
        "    2. read the image\n",
        "    3. display the image\n",
        "    '''\n",
        "    capture_image = cv2.VideoCapture(video_path)\n",
        "    ret, frame = capture_image.read()\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    ax.imshow(frame)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:07.16062Z",
          "iopub.execute_input": "2023-12-09T09:38:07.161518Z",
          "iopub.status.idle": "2023-12-09T09:38:07.167119Z",
          "shell.execute_reply.started": "2023-12-09T09:38:07.161482Z",
          "shell.execute_reply": "2023-12-09T09:38:07.166259Z"
        },
        "trusted": true,
        "id": "DuYRJq3emZuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_file in fake_train_sample_video:\n",
        "    display_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:09.993694Z",
          "iopub.execute_input": "2023-12-09T09:38:09.994385Z",
          "iopub.status.idle": "2023-12-09T09:38:12.613738Z",
          "shell.execute_reply.started": "2023-12-09T09:38:09.99435Z",
          "shell.execute_reply": "2023-12-09T09:38:12.612799Z"
        },
        "trusted": true,
        "id": "6XAec5yRmZuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try now the same for few of the images that are real."
      ],
      "metadata": {
        "id": "DgHTZLQSmZul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few Real Videos"
      ],
      "metadata": {
        "id": "6xh0_ISGmZul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='REAL'].sample(3).index)\n",
        "real_train_sample_video"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:19.403635Z",
          "iopub.execute_input": "2023-12-09T09:38:19.403997Z",
          "iopub.status.idle": "2023-12-09T09:38:19.412111Z",
          "shell.execute_reply.started": "2023-12-09T09:38:19.403971Z",
          "shell.execute_reply": "2023-12-09T09:38:19.411062Z"
        },
        "trusted": true,
        "id": "9tutSU1FmZum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_file in real_train_sample_video:\n",
        "    display_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:21.941694Z",
          "iopub.execute_input": "2023-12-09T09:38:21.942061Z",
          "iopub.status.idle": "2023-12-09T09:38:24.559673Z",
          "shell.execute_reply.started": "2023-12-09T09:38:21.94203Z",
          "shell.execute_reply": "2023-12-09T09:38:24.55858Z"
        },
        "trusted": true,
        "id": "OPhCzE8umZum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Videos with same original"
      ],
      "metadata": {
        "id": "ktcePx2ZmZun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look now to set of samples with the same original."
      ],
      "metadata": {
        "id": "4HObUbAkmZun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata['original'].value_counts()[0:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:30.401856Z",
          "iopub.execute_input": "2023-12-09T09:38:30.402979Z",
          "iopub.status.idle": "2023-12-09T09:38:30.415327Z",
          "shell.execute_reply.started": "2023-12-09T09:38:30.402937Z",
          "shell.execute_reply": "2023-12-09T09:38:30.414299Z"
        },
        "trusted": true,
        "id": "UrtXQbZYmZun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pick one of the originals with largest number of samples.\n",
        "\n",
        "We also modify our visualization function to work with multiple images."
      ],
      "metadata": {
        "id": "D7lO9Z-6mZuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_from_video_list(video_path_list, video_folder=TRAIN_SAMPLE_FOLDER):\n",
        "    '''\n",
        "    input: video_path_list - path for video\n",
        "    process:\n",
        "    0. for each video in the video path list\n",
        "        1. perform a video capture from the video\n",
        "        2. read the image\n",
        "        3. display the image\n",
        "    '''\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(2,3,figsize=(16,8))\n",
        "    # we only show images extracted from the first 6 videos\n",
        "    for i, video_file in enumerate(video_path_list[0:6]):\n",
        "        video_path = os.path.join(DATA_FOLDER, video_folder,video_file)\n",
        "        capture_image = cv2.VideoCapture(video_path)\n",
        "        ret, frame = capture_image.read()\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        ax[i//3, i%3].imshow(frame)\n",
        "        ax[i//3, i%3].set_title(f\"Video: {video_file}\")\n",
        "        ax[i//3, i%3].axis('on')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:34.82578Z",
          "iopub.execute_input": "2023-12-09T09:38:34.826167Z",
          "iopub.status.idle": "2023-12-09T09:38:34.834064Z",
          "shell.execute_reply.started": "2023-12-09T09:38:34.826136Z",
          "shell.execute_reply": "2023-12-09T09:38:34.83305Z"
        },
        "trusted": true,
        "id": "_kOZ8SmpmZuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same_original_fake_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.original=='atvmxvwyns.mp4'].index)\n",
        "display_image_from_video_list(same_original_fake_train_sample_video)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:38:38.029774Z",
          "iopub.execute_input": "2023-12-09T09:38:38.030136Z",
          "iopub.status.idle": "2023-12-09T09:38:42.226604Z",
          "shell.execute_reply.started": "2023-12-09T09:38:38.030107Z",
          "shell.execute_reply": "2023-12-09T09:38:42.22565Z"
        },
        "trusted": true,
        "id": "Ct8PrLK0mZup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test video files"
      ],
      "metadata": {
        "id": "Bl3faYKLmZup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also look to few of the test data files."
      ],
      "metadata": {
        "id": "XI0mCIX2mZup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_videos = pd.DataFrame(list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER))), columns=['video'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:14.219771Z",
          "iopub.execute_input": "2023-12-09T09:39:14.220526Z",
          "iopub.status.idle": "2023-12-09T09:39:14.229219Z",
          "shell.execute_reply.started": "2023-12-09T09:39:14.220488Z",
          "shell.execute_reply": "2023-12-09T09:39:14.228099Z"
        },
        "trusted": true,
        "id": "wv80kXPHmZuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_videos.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:17.203407Z",
          "iopub.execute_input": "2023-12-09T09:39:17.204126Z",
          "iopub.status.idle": "2023-12-09T09:39:17.212507Z",
          "shell.execute_reply.started": "2023-12-09T09:39:17.204083Z",
          "shell.execute_reply": "2023-12-09T09:39:17.211692Z"
        },
        "trusted": true,
        "id": "tcJtbYSmmZuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize now one of the videos."
      ],
      "metadata": {
        "id": "SAAnzfGtmZur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_image_from_video(os.path.join(DATA_FOLDER, TEST_FOLDER, test_videos.iloc[2].video))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:20.213638Z",
          "iopub.execute_input": "2023-12-09T09:39:20.21438Z",
          "iopub.status.idle": "2023-12-09T09:39:21.110934Z",
          "shell.execute_reply.started": "2023-12-09T09:39:20.214345Z",
          "shell.execute_reply": "2023-12-09T09:39:21.110105Z"
        },
        "trusted": true,
        "id": "amajh5AlmZur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Play video files"
      ],
      "metadata": {
        "id": "Xb-yBBwRmZur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look to few fake videos."
      ],
      "metadata": {
        "id": "YK3PnbJNmZus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_videos = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].index)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:25.777441Z",
          "iopub.execute_input": "2023-12-09T09:39:25.778352Z",
          "iopub.status.idle": "2023-12-09T09:39:25.78382Z",
          "shell.execute_reply.started": "2023-12-09T09:39:25.778316Z",
          "shell.execute_reply": "2023-12-09T09:39:25.782852Z"
        },
        "trusted": true,
        "id": "RckyeJ1nmZus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def play_video(video_file, subset=TRAIN_SAMPLE_FOLDER):\n",
        "    '''\n",
        "    Display video\n",
        "    param: video_file - the name of the video file to display\n",
        "    param: subset - the folder where the video file is located (can be TRAIN_SAMPLE_FOLDER or TEST_Folder)\n",
        "    '''\n",
        "    video_url = open(os.path.join(DATA_FOLDER, subset,video_file),'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(video_url).decode()\n",
        "    return HTML(\"\"\"<video width=500 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)\n",
        "\n",
        "play_video(fake_videos[10])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:45.512744Z",
          "iopub.execute_input": "2023-12-09T09:39:45.513602Z",
          "iopub.status.idle": "2023-12-09T09:39:45.92925Z",
          "shell.execute_reply.started": "2023-12-09T09:39:45.513571Z",
          "shell.execute_reply": "2023-12-09T09:39:45.928208Z"
        },
        "trusted": true,
        "id": "fl9IRbrSmZut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From visual inspection of these fakes videos, in some cases is very easy to spot the anomalies created when engineering the deep fake, in some cases is more difficult."
      ],
      "metadata": {
        "id": "FuhM1QmomZut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "HQ_PI2JamZuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A CNN-RNN Architecture"
      ],
      "metadata": {
        "id": "jf3-sfNemZuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:56.691281Z",
          "iopub.execute_input": "2023-12-09T09:39:56.691932Z",
          "iopub.status.idle": "2023-12-09T09:39:56.696565Z",
          "shell.execute_reply.started": "2023-12-09T09:39:56.691897Z",
          "shell.execute_reply": "2023-12-09T09:39:56.695524Z"
        },
        "trusted": true,
        "id": "1GbJ7jfAmZuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this example we will do the following:\n",
        "\n",
        "* Capture the frames of a video.\n",
        "* Extract frames from the videos until a maximum frame count is reached.\n",
        "* In the case, where a video's frame count is lesser than the maximum frame count we will pad the video with zeros."
      ],
      "metadata": {
        "id": "mbsEghXAmZuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:39:59.762521Z",
          "iopub.execute_input": "2023-12-09T09:39:59.763426Z",
          "iopub.status.idle": "2023-12-09T09:39:59.771592Z",
          "shell.execute_reply.started": "2023-12-09T09:39:59.76339Z",
          "shell.execute_reply": "2023-12-09T09:39:59.770602Z"
        },
        "trusted": true,
        "id": "KGUEdVJymZuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use a pre-trained network to extract meaningful features from the extracted frames. The Keras Applications module provides a number of state-of-the-art models pre-trained on the ImageNet-1k dataset. We will be using the InceptionV3 model for this purpose."
      ],
      "metadata": {
        "id": "O9y7MolcmZuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:40:05.485629Z",
          "iopub.execute_input": "2023-12-09T09:40:05.486005Z",
          "iopub.status.idle": "2023-12-09T09:40:12.956618Z",
          "shell.execute_reply.started": "2023-12-09T09:40:05.485977Z",
          "shell.execute_reply": "2023-12-09T09:40:12.955774Z"
        },
        "trusted": true,
        "id": "cmAYygAVmZuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can put all the pieces together to create our data processing utility."
      ],
      "metadata": {
        "id": "gNDioA2AmZuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = list(df.index)\n",
        "    labels = df[\"label\"].values\n",
        "    labels = np.array(labels == 'FAKE').astype(int)\n",
        "\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:40:17.739948Z",
          "iopub.execute_input": "2023-12-09T09:40:17.740348Z",
          "iopub.status.idle": "2023-12-09T09:40:17.751232Z",
          "shell.execute_reply.started": "2023-12-09T09:40:17.740316Z",
          "shell.execute_reply": "2023-12-09T09:40:17.750157Z"
        },
        "trusted": true,
        "id": "u0ixEPPMmZuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we don't have test labels we split the training data to find its performance in unseen data"
      ],
      "metadata": {
        "id": "Nyix9aD3mZux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Train_set, Test_set = train_test_split(train_sample_metadata,test_size=0.1,random_state=42,stratify=train_sample_metadata['label'])\n",
        "\n",
        "print(Train_set.shape, Test_set.shape )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:40:24.037252Z",
          "iopub.execute_input": "2023-12-09T09:40:24.038352Z",
          "iopub.status.idle": "2023-12-09T09:40:24.554465Z",
          "shell.execute_reply.started": "2023-12-09T09:40:24.038306Z",
          "shell.execute_reply": "2023-12-09T09:40:24.553432Z"
        },
        "trusted": true,
        "id": "9UleDYgxmZux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels = prepare_all_videos(Train_set, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(Test_set, \"test\")\n",
        "\n",
        "# Assuming train_data is a tuple with two elements: (frame_features, frame_masks)\n",
        "frame_features_shape = train_data[0].shape if train_data and len(train_data) > 0 else None\n",
        "frame_masks_shape = train_data[1].shape if train_data and len(train_data) > 1 else None\n",
        "\n",
        "print(f\"Frame features in train set: {frame_features_shape}\")\n",
        "print(f\"Frame masks in train set: {frame_masks_shape}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:40:28.761271Z",
          "iopub.execute_input": "2023-12-09T09:40:28.761945Z",
          "iopub.status.idle": "2023-12-09T09:40:28.840851Z",
          "shell.execute_reply.started": "2023-12-09T09:40:28.761913Z",
          "shell.execute_reply": "2023-12-09T09:40:28.839811Z"
        },
        "trusted": true,
        "id": "Tq-YTXFPmZuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The sequence model"
      ],
      "metadata": {
        "id": "ToilSwnMmZuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can feed this data to a sequence model consisting of recurrent layers like GRU."
      ],
      "metadata": {
        "id": "DZNFYRKymZuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "# Refer to the following tutorial to understand the significance of using `mask`:\n",
        "# https://keras.io/api/layers/recurrent_layers/gru/\n",
        "x = keras.layers.GRU(16, return_sequences=True)(\n",
        "    frame_features_input, mask=mask_input\n",
        ")\n",
        "x = keras.layers.GRU(8)(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:40:33.875292Z",
          "iopub.execute_input": "2023-12-09T09:40:33.87613Z",
          "iopub.status.idle": "2023-12-09T09:40:35.959428Z",
          "shell.execute_reply.started": "2023-12-09T09:40:33.876088Z",
          "shell.execute_reply": "2023-12-09T09:40:35.958464Z"
        },
        "trusted": true,
        "id": "Z6fgdF3hmZuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:41:46.402367Z",
          "iopub.execute_input": "2023-12-09T09:41:46.403231Z",
          "iopub.status.idle": "2023-12-09T09:41:59.043556Z",
          "shell.execute_reply.started": "2023-12-09T09:41:46.403194Z",
          "shell.execute_reply": "2023-12-09T09:41:59.042124Z"
        },
        "trusted": true,
        "id": "6Ph61j_9mZuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = keras.callbacks.ModelCheckpoint('./', save_weights_only=True, save_best_only=True)\n",
        "history = model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_data=([test_data[0], test_data[1]],test_labels),\n",
        "        callbacks=[checkpoint],\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=8\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:42:30.862289Z",
          "iopub.execute_input": "2023-12-09T09:42:30.86314Z",
          "iopub.status.idle": "2023-12-09T09:42:33.069853Z",
          "shell.execute_reply.started": "2023-12-09T09:42:30.863069Z",
          "shell.execute_reply": "2023-12-09T09:42:33.068582Z"
        },
        "trusted": true,
        "id": "Kch0QS8bmZuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "lQRPJ0TlmZuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    frames = load_video(os.path.join(DATA_FOLDER, TEST_FOLDER,path))\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    return model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "\n",
        "def to_gif(images):\n",
        "    converted_images = images.astype(np.uint8)\n",
        "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
        "    return embed.embed_file(\"animation.gif\")\n",
        "\n",
        "\n",
        "test_video = input(\"Enter the path of the video: \")\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "if(sequence_prediction(test_video)>=0.5):\n",
        "    print(f'The predicted class of the video is FAKE')\n",
        "else:\n",
        "    print(f'The predicted class of the video is REAL')\n",
        "\n",
        "play_video(test_video,TEST_FOLDER)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:25:04.656711Z",
          "iopub.execute_input": "2023-12-09T09:25:04.657085Z",
          "iopub.status.idle": "2023-12-09T09:25:26.463918Z",
          "shell.execute_reply.started": "2023-12-09T09:25:04.657035Z",
          "shell.execute_reply": "2023-12-09T09:25:26.463194Z"
        },
        "trusted": true,
        "id": "j2p_1YkHmZu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import imageio\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming you have defined MAX_SEQ_LENGTH, NUM_FEATURES, DATA_FOLDER, TEST_FOLDER, and feature_extractor\n",
        "\n",
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    frames = load_video(os.path.join(DATA_FOLDER, TEST_FOLDER, path))\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    return model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "def visualize_frames_with_predictions(video_path):\n",
        "    frames = load_video(os.path.join(DATA_FOLDER, TEST_FOLDER, video_path))\n",
        "\n",
        "    for i, frame in enumerate(frames):\n",
        "        frame_features, frame_mask = prepare_single_video(np.array([frame]))\n",
        "        prediction = sequence_prediction(video_path)\n",
        "\n",
        "        # Print or save the individual frame along with its prediction\n",
        "        print(f\"Frame {i}: {'FAKE' if prediction >= 0.5 else 'REAL'}\")\n",
        "        plt.imshow(frame)  # Assuming you have matplotlib for visualization\n",
        "        plt.show()\n",
        "\n",
        "test_video = input(\"Enter the path of the video: \")\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "# Visualize frames with predictions\n",
        "visualize_frames_with_predictions(test_video)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T09:43:14.741376Z",
          "iopub.execute_input": "2023-12-09T09:43:14.742288Z",
          "iopub.status.idle": "2023-12-09T09:44:50.757089Z",
          "shell.execute_reply.started": "2023-12-09T09:43:14.74225Z",
          "shell.execute_reply": "2023-12-09T09:44:50.755938Z"
        },
        "trusted": true,
        "id": "HgNF5DtImZu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}